# Cheat Sheet â€“ szybkie przypomnienie kluczowych konceptÃ³w

Szybkie przypomnienie najwaÅ¼niejszych konceptÃ³w z bootcampu ML. SzczegÃ³Å‚owe wyjaÅ›nienia znajdziesz w plikach summary_p6.md - summary_p11.md.

---

## ðŸ“š Importy (standardowe)

```python
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
import statsmodels.api as sm
```

**Konfiguracja:**
```python
np.random.seed(42)
sns.set(font_scale=1.3)
```

---

## ðŸ“Š Przygotowanie danych

### Wczytanie danych
```python
df = pd.read_csv('path/to/file.csv')
df = df_raw.copy()
```

### Eksploracja danych (EDA)
```python
df.info()
df.describe()
df.describe(include='category')
df.isnull().sum()
df.duplicated()
df.drop_duplicates()
```

### PodziaÅ‚ na cechy i target
```python
target = data.pop('charges')
X_train, X_test, y_train, y_test = train_test_split(
    data, target, test_size=0.2, random_state=42
)
```

---

## ðŸ”¢ Kodowanie zmiennych kategorycznych

### One-Hot Encoding
```python
df_dummies = pd.get_dummies(df, drop_first=True)
```

**Dlaczego `drop_first=True`:**
- Unika puÅ‚apki zmiennych fikcyjnych (dummy variable trap)
- Redukuje kolinearnoÅ›Ä‡
- Jedna kategoria jest referencyjna (domyÅ›lna)

**PrzykÅ‚ad:**
- `sex`: ['male', 'female'] â†’ `sex_male` (0 lub 1)
- `region`: 4 kategorie â†’ 3 kolumny (jedna usuniÄ™ta)

### Konwersja na kategorie
```python
cat_cols = [col for col in df.columns if df[col].dtype == 'O']
for cat in cat_cols:
    df[cat] = df[cat].astype('category')
```

---

## ðŸ¤– Regresja liniowa (scikit-learn)

### Podstawowy model
```python
regressor = LinearRegression()
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
```

### Parametry modelu
```python
regressor.coef_
regressor.intercept_
```

**RÃ³wnanie:** `y = intercept_ + coef_[0] * x1 + coef_[1] * x2 + ...`

### Ocena modelu
```python
regressor.score(X_train, y_train)
regressor.score(X_test, y_test)
```

**`score()` zwraca RÂ²:**
- 1.0 = idealne dopasowanie
- 0.0 = model nie lepszy niÅ¼ Å›rednia
- < 0 = model gorszy niÅ¼ Å›rednia

### Metryki bÅ‚Ä™dÃ³w
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
```

---

## ðŸ“ˆ Regresja OLS (statsmodels)

### Przygotowanie danych
```python
X_train_ols = pd.get_dummies(X_train, drop_first=True)
predictors = ['const'] + list(X_train_ols.columns)
X_train_ols = X_train_ols.values.astype(float)
X_train_ols = sm.add_constant(X_train_ols)
```

### Model OLS
```python
ols = sm.OLS(endog=y_train.values, exog=X_train_ols).fit()
print(ols.summary(xname=predictors))
```

**Interpretacja p-value:**
- **p < 0.05** â†’ zmienna istotna statystycznie
- **p â‰¥ 0.05** â†’ zmienna nieistotna (moÅ¼na usunÄ…Ä‡)

---

## ðŸ“‰ Wizualizacje

### Podstawowe (matplotlib)
```python
plt.figure(figsize=(8, 6))
plt.scatter(X, y, label='dane')
plt.plot(X, y_pred, color='red', label='model')
plt.legend()
plt.show()
```

### Histogram (pandas)
```python
df['column'].plot(kind='hist', bins=50, figsize=(8, 6))
```

### Wykresy pandas
```python
df.plot(kind='hist')    # histogram
df.plot(kind='line')    # liniowy
df.plot(kind='bar')     # sÅ‚upkowy
df.plot(kind='barh')    # poziomy sÅ‚upkowy
df.plot(kind='box')     # pudeÅ‚kowy
df.plot(kind='scatter') # punktowy
df.plot(kind='pie')     # koÅ‚owy
```

### Heatmap korelacji (seaborn)
```python
corr = df.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()
```

### Plotly Express (interaktywne)
```python
import plotly.express as px

fig = px.histogram(df, x='charges', facet_col='smoker')
fig.show()
```

---

## ðŸ” Analiza danych

### Statystyki opisowe
```python
df.describe().T
df.value_counts()
df['column'].value_counts()
```

### Korelacja
```python
df.corr()
df.corr()['target'].sort_values(ascending=False)
```

### Analiza bÅ‚Ä™dÃ³w
```python
predictions = pd.DataFrame({
    'y_true': y_test,
    'y_pred': y_pred
})
predictions['error'] = predictions['y_true'] - predictions['y_pred']
predictions['error'].plot(kind='hist', bins=50)
```

---

## ðŸŽ¯ Gradient Descent (rÄ™czna implementacja)

```python
eta = 0.01
weights = np.random.randn(2, 1)

for i in range(3000):
    gradient = (2 / m) * X.T.dot(X.dot(weights) - Y)
    weights = weights - eta * gradient
```

**Co siÄ™ dzieje:**
1. Predykcja: `X.dot(weights)`
2. BÅ‚Ä…d: `X.dot(weights) - Y`
3. Gradient: `(2/m) * X.T.dot(bÅ‚Ä…d)`
4. Aktualizacja: `weights = weights - eta * gradient`

---

## ðŸ”„ Selekcja zmiennych

### Automatyczna Backward Elimination
```python
sl = 0.05
while True:
    ols = sm.OLS(endog=y_train.values, exog=X_train_numpy).fit()
    max_pval = max(ols.pvalues.astype('float'))
    if max_pval > sl:
        max_idx = np.argmax(ols.pvalues.astype('float'))
        X_train_numpy = np.delete(X_train_numpy, max_idx, axis=1)
        predictors.remove(predictors[max_idx])
    else:
        break
```

**Funkcje NumPy:**
- `np.argmax(array)` â†’ indeks elementu z najwyÅ¼szÄ… wartoÅ›ciÄ…
- `np.delete(array, idx, axis=1)` â†’ usuwa kolumnÄ™ o indeksie idx

### RÄ™czne usuwanie kolumn (numpy)
```python
X_selected = X_train_ols[:, [0, 1, 2, 3, 5]]
predictors.remove('column_name')
```

### Zapis modelu do pliku
```python
ols.save('model.pickle')

import pickle
with open('model.pickle', 'rb') as f:
    loaded_model = pickle.load(f)
```

---

## âš ï¸ NajczÄ™stsze bÅ‚Ä™dy i rozwiÄ…zania

### Problem: TypeError z stringami w statsmodels
**RozwiÄ…zanie:** `X_train_ols.values.astype(float)`

### Problem: Pandas Series w statsmodels
**RozwiÄ…zanie:** `y_train.values` (konwersja na numpy array)

### Problem: Boolean w numpy array
**RozwiÄ…zanie:** `.astype(float)` po `get_dummies()`

### Problem: KolinearnoÅ›Ä‡ w one-hot encoding
**RozwiÄ…zanie:** `drop_first=True` w `get_dummies()`

---

## ðŸ“ Dobre praktyki

1. **Zawsze uÅ¼ywaj `random_state`** dla powtarzalnoÅ›ci
2. **Zachowaj oryginalne dane:** `df = df_raw.copy()`
3. **Trenuj na train, oceniaj na test** â€“ nigdy odwrotnie!
4. **Sprawdzaj overfitting:** porÃ³wnaj score na train vs test
5. **EDA przed modelowaniem** â€“ zrozum dane najpierw
6. **Usuwaj duplikaty** przed trenowaniem
7. **Koduj kategorie** przed uÅ¼yciem w modelach ML

---

## ðŸŽ“ Kluczowe koncepty

### Overfitting vs Underfitting
- **Overfitting:** score(train) >> score(test) â†’ model zapamiÄ™taÅ‚ dane
- **Underfitting:** oba niskie â†’ model za prosty
- **Idealnie:** podobne wyniki na train i test

### RÂ² vs MAE
- **RÂ²:** procent wyjaÅ›nionej wariancji (0-1)
- **MAE:** Å›redni bÅ‚Ä…d w jednostkach targetu (Å‚atwiejsze do zrozumienia)

### Train/Test Split
- **80/20** lub **75/25** to standard
- **random_state** dla powtarzalnoÅ›ci
- **Nigdy nie oceniaj na danych treningowych!**

---

## ðŸ“š Mapowanie konceptÃ³w do plikÃ³w

- **p6.py** â†’ Gradient Descent (rÄ™czna implementacja)
- **p7.py** â†’ Regresja liniowa scikit-learn (syntetyczne dane)
- **p8.py** â†’ Train/test split, ocena modelu
- **p9.py** â†’ Rzeczywiste dane, EDA, feature engineering
- **p10.py** â†’ OLS statsmodels, selekcja zmiennych

---

> **Tip:** UÅ¼ywaj tego cheat sheet jako szybkiego przypomnienia. SzczegÃ³Å‚owe wyjaÅ›nienia znajdziesz w plikach summary_p*.md.
