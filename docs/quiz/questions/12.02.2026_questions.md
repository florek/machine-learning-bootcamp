# Quiz ML Bootcamp – 12.02.2026

---

## Pytanie 1 [łatwe]

W gradient descent wagi aktualizuje się w każdej iteracji. Który wzór jest poprawny?

A) `weights = weights - eta * gradient`  
B) `weights = weights + eta * gradient`  
C) `weights = eta * gradient`  
D) `weights = weights * eta * gradient`

---

## Pytanie 2 [średnie]

Gdy regressor.score(X_train, y_train) jest dużo wyższy niż regressor.score(X_test, y_test), co to oznacza?

A) Underfitting – model jest za prosty.  
B) Overfitting – model zapamiętał dane treningowe.  
C) Błędny podział train/test.  
D) Metryka R² nie nadaje się do oceny.

---

## Pytanie 3 [średnie]

Po co w pd.get_dummies() używamy drop_first=True?

A) Aby usunąć pierwszą kolumnę alfabetycznie.  
B) Aby przyspieszyć uczenie.  
C) Aby uniknąć pułapki zmiennych fikcyjnych i kolinearności.  
D) Aby zmniejszyć liczbę wierszy.

---

## Pytanie 4 [łatwe]

Co oznacza test_size=0.25 w train_test_split?

A) 25% danych idzie do zbioru treningowego.  
B) Dokładnie 25 próbek trafia do testu.  
C) 25% danych idzie do walidacji.  
D) 25% danych idzie do zbioru testowego.

---

## Pytanie 5 [łatwe]

Która metryka jest w tych samych jednostkach co zmienna docelowa (np. złote) i jest czytelna biznesowo?

A) Mean Absolute Error (MAE).  
B) R².  
C) MSE.  
D) p-value.

---

## Pytanie 6 [średnie]

W modelu OLS (statsmodels) zmienna jest uznawana za istotną statystycznie, gdy:

A) p-value > 0.05.  
B) p-value < 0.05.  
C) p-value ≥ 0.05.  
D) p-value = 0.

---

## Pytanie 7 [średnie]

W ręcznym gradient descent do macierzy cech dodajemy kolumnę jedynek. Po co?

A) Zwiększa liczbę iteracji.  
B) Zastępuje pierwszą cechę.  
C) Reprezentuje wyraz wolny (intercept) w modelu Y = w0·1 + w1·X.  
D) Służy do normalizacji.

---

## Pytanie 8 [trudne]

W make_regression(..., noise=10, ...) parametr noise określa:

A) Liczbę cech szumowych.  
B) Liczbę obserwacji z brakami.  
C) Ziarno generatora.  
D) Poziom szumu dodawanego do zmiennej docelowej.

---

## Pytanie 9 [łatwe]

Do czego w gradient descent służy obliczany w każdej iteracji gradient?

A) Określa kierunek i wielkość kroku aktualizacji wag, aby zmniejszyć błąd.  
B) Określa końcowe R².  
C) Służy do podziału na train/test.  
D) Zastępuje learning rate.

---

## Pytanie 10 [trudne]

W automatycznej backward elimination w każdej iteracji usuwa się zmienną, która:

A) Ma najniższy współczynnik.  
B) Ma najwyższe p-value spośród nieistotnych (p > poziom istotności).  
C) Ma najwyższą korelację z targetem.  
D) Ma najniższe p-value.

---

## Pytanie 11 [średnie]

Co zwraca np.argmax(ols.pvalues.astype('float')) w kontekście backward elimination?

A) Maksymalną wartość p-value.  
B) Liczbę zmiennych istotnych.  
C) Indeks zmiennej (kolumny) o najwyższym p-value.  
D) Listę nazw zmiennych do usunięcia.

---

## Pytanie 12 [średnie]

Regresja wielomianowa w scikit-learn to w praktyce:

A) Osobny algorytm PolynomialRegression.  
B) Model nieliniowy zamiast LinearRegression.  
C) Tylko zwiększenie stopnia bez nowych cech.  
D) Rozszerzenie cech (PolynomialFeatures: 1, X, X², …) + zwykła LinearRegression.

---

## Pytanie 13 [łatwe]

Przed modelem OLS w statsmodels do macierzy cech dodaje się kolumnę stałej. Jak?

A) sm.add_constant().  
B) np.ones().  
C) pd.get_dummies().  
D) np.append().

---

## Pytanie 14 [trudne]

W równaniu Y = w0·1 + w1·X (gradient descent) w0 to:

A) Współczynnik kierunkowy (nachylenie).  
B) Wyraz wolny (intercept).  
C) Learning rate.  
D) Liczba iteracji.

---

## Pytanie 15 [średnie]

Histogram błędów (y_test - y_pred) dobrego modelu regresji powinien:

A) Być płaski.  
B) Mieć ostry pik z dala od zera.  
C) Być w przybliżeniu symetryczny wokół zera, kształt zbliżony do normalnego.  
D) Być silnie asymetryczny.

---

## Pytanie 16 [trudne]

Forward Selection w porównaniu z Backward Elimination:

A) Startuje z pełnym modelem i usuwa zmienne.  
B) Używa tylko p-value dla intercept.  
C) Nie stosuje poziomu istotności.  
D) Startuje od pustego modelu i dodaje zmienne po kolei.

---

## Pytanie 17 [trudne]

Przy regresji wielomianowej z wysokim stopniem i małą liczbą obserwacji dokumentacja zaleca:

A) Regularyzację (Ridge/Lasso) lub niższy stopień – ryzyko przeuczenia.  
B) Zawsze degree=2.  
C) Zwiększenie liczby cech wejściowych.  
D) Pominięcie train/test split.

---

## Pytanie 18 [średnie]

Wyrażenie target = data.pop('charges') przy przygotowaniu danych do modelu:

A) Dodaje kolumnę 'charges' do data.  
B) Usuwa kolumnę z DataFrame i zwraca ją jako Series; zapobiega użyciu targetu jako cechy.  
C) Kopiuje kolumnę bez usuwania z data.  
D) Zwraca pierwszą wartość kolumny 'charges'.

---

## Pytanie 19 [łatwe]

Parametr stratify=y w train_test_split() służy do:

A) Zwiększenia rozmiaru zbioru testowego.  
B) Ustawienia ziarna (random_state).  
C) Zachowania proporcji klas w train i test.  
D) Usunięcia duplikatów przed podziałem.

---

## Pytanie 20 [średnie]

R² = 0 dla modelu regresji oznacza, że:

A) Model idealnie dopasowuje dane.  
B) Wszystkie współczynniki są równe zero.  
C) Błąd predykcji jest maksymalny.  
D) Model nie wyjaśnia wariancji lepiej niż prosta średnia.
