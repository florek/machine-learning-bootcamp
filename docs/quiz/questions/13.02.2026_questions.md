# Quiz ML Bootcamp – 13.02.2026

---

## Pytanie 1 [średnie]

Przy imputacji braków w cechach numerycznych SimpleImputer(strategy="mean") może być niewłaściwy gdy:

A) Braki są losowe.  
B) Cecha jest ciągła.  
C) Dane zawierają outliery – wtedy rozważ median.  
D) Nie ma wartości domyślnej.

---

## Pytanie 2 [łatwe]

Który wzór opisuje aktualizację wag w gradient descent?

A) weights = weights - eta * gradient  
B) weights = weights + eta * gradient  
C) weights = eta * gradient  
D) weights = weights / gradient

---

## Pytanie 3 [trudne]

W backward elimination pętla kończy się (break), gdy:

A) Osiągnięto maksymalną liczbę iteracji.  
B) Nie ma już kolumn do usunięcia.  
C) Wszystkie pozostałe zmienne mają p-value ≤ poziomu istotności.  
D) R² spadło poniżej progu.

---

## Pytanie 4 [średnie]

Po co w train_test_split podaje się random_state?

A) Aby zwiększyć rozmiar zbioru testowego.  
B) Aby uzyskać powtarzalność podziału przy każdym uruchomieniu.  
C) Aby zachować proporcje klas.  
D) Aby usunąć duplikaty.

---

## Pytanie 5 [średnie]

W pipeline z danymi insurance po get_dummies() przed przekazaniem do sm.OLS() wykonuje się .values.astype(float). Dlaczego?

A) Aby przyspieszyć obliczenia.  
B) Aby zachować proporcje.  
C) statsmodels wymaga numpy array float; boolean z get_dummies muszą być 1.0/0.0.  
D) Aby usunąć braki.

---

## Pytanie 6 [łatwe]

Równanie modelu LinearRegression to:

A) y = intercept_ + coef_[0]*x1 + coef_[1]*x2 + …  
B) y = coef_ * x  
C) y = eta * gradient  
D) y = mean(y)

---

## Pytanie 7 [trudne]

Stepwise Selection w porównaniu z samym Backward Elimination to:

A) To samo, inna nazwa.  
B) Start od pustego modelu.  
C) Tylko regularyzacja L1.  
D) Kombinacja forward i backward – można dodawać i usuwać zmienne.

---

## Pytanie 8 [średnie]

df.corr() zwraca:

A) Liczbę brakujących wartości.  
B) Macierz współczynników korelacji Pearsona między kolumnami.  
C) Listę duplikatów.  
D) Rozkład targetu.

---

## Pytanie 9 [średnie]

Gdy score na zbiorze treningowym jest dużo wyższy niż na testowym, zalecane działanie to m.in.:

A) Zwiększenie złożoności modelu.  
B) Dodanie większej liczby cech bez walidacji.  
C) Podejrzenie overfittingu; rozważ prostszy model lub regularyzację.  
D) Ocenianie tylko na train.

---

## Pytanie 10 [łatwe]

data.pop('target') przy przygotowaniu danych do modelu:

A) Dodaje kolumnę 'target' do data.  
B) Zwraca pierwszą wartość kolumny.  
C) Usuwa kolumnę z DataFrame i zwraca ją (cechy i target osobno).  
D) Tworzy kopię bez usuwania.

---

## Pytanie 11 [trudne]

W Normal Equation θ = (XᵀX)⁻¹Xᵀy – theta[1] (drugi element) to zwykle:

A) Intercept (wyraz wolny).  
B) Błąd MSE.  
C) Liczba cech.  
D) Współczynnik kierunkowy (dla pierwszej cechy).

---

## Pytanie 12 [średnie]

Dlaczego w one-hot encoding stosuje się drop_first=True?

A) Aby przyspieszyć trenowanie.  
B) Uniknięcie pułapki zmiennych fikcyjnych i redukcja kolinearności.  
C) Aby zmniejszyć liczbę wierszy.  
D) Aby usunąć ostatnią kolumnę.

---

## Pytanie 13 [średnie]

Metryka MAE (Mean Absolute Error) jest wyrażona w:

A) Procentach (0–100).  
B) Jednostkach zmiennej docelowej.  
C) Liczbie cech.  
D) Wartości p-value.

---

## Pytanie 14 [łatwe]

X.reshape(n, 1) dla jednej cechy przed przekazaniem do scikit-learn jest potrzebne, bo:

A) Biblioteka oczekuje macierzy 2D (próbki × cechy).  
B) Aby usunąć braki.  
C) Aby dodać intercept.  
D) Aby przyspieszyć obliczenia.

---

## Pytanie 15 [trudne]

Przy wysokim stopniu PolynomialFeatures i małej liczbie obserwacji ryzyko przeuczenia zmniejsza:

A) Zwiększenie stopnia wielomianu.  
B) Pominięcie train/test split.  
C) Regularyzacja (Ridge/Lasso) lub niższy stopień.  
D) Więcej cech wejściowych bez transformacji.

---

## Pytanie 16 [średnie]

W gradient descent gradient dla MSE oblicza się jako:

A) (1/m) * X.T.dot(X.dot(weights) - Y)  
B) X.T.dot(Y)  
C) weights - Y  
D) (2/m) * X.T.dot(X.dot(weights) - Y)

---

## Pytanie 17 [łatwe]

W OLS (statsmodels) zmienna jest uznawana za nieistotną statystycznie, gdy:

A) p-value < 0.05  
B) p-value = 0  
C) p-value ≥ 0.05  
D) Współczynnik jest ujemny

---

## Pytanie 18 [łatwe]

train_test_split(..., test_size=0.2) oznacza:

A) 20% danych do zbioru testowego, 80% do treningu.  
B) 20 próbek do testu.  
C) 20% do walidacji.  
D) 20 cech w zbiorze testowym.

---

## Pytanie 19 [trudne]

Zapis dopasowanego modelu OLS do pliku (np. do późniejszego wczytania bez ponownego uczenia) wykonuje się przez:

A) regressor.save()  
B) ols.save('model.pickle')  
C) pd.to_pickle(ols)  
D) Tylko przez zapis współczynników do CSV

---

## Pytanie 20 [średnie]

Histogram błędów predykcji (y_test - y_pred) dobrze dopasowanego modelu powinien być:

A) Płaski.  
B) W przybliżeniu symetryczny wokół zera, kształt zbliżony do normalnego.  
C) Z jednym ostrym pikiem z dala od zera.  
D) Silnie asymetryczny.
